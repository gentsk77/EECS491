{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 491 Assignment 3\n",
    "\n",
    "  Yue Shu  \n",
    "  Spring 2019  \n",
    "  Prof. Lewicki  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1. Multivariate Gaussians\n",
    "\n",
    "## 1.1 Consider the 2D normal distribution \n",
    "\n",
    "**$$ p(x,y) \\sim \\mathcal{N}(\\mathbf{\\mu}, \\mathbf{\\Sigma}) $$**\n",
    "\n",
    "**Define three separate 2D covariance matrices $\\mathbf{\\Sigma}$ for each of the following cases: $x$ and $y$ are uncorrelated; $x$ and $y$ are correlated; and $x$ and $y$ are anti-correlated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix $\\Sigma$ could be defined as below in general:\n",
    "\n",
    "$$  \n",
    "\\Sigma =  \\begin{bmatrix} \\Sigma_{x x} & \\Sigma_{x y} \\\\ \\Sigma_{y x} & \\Sigma_{y y} \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $x$ and $y$ are uncorrelated\n",
    "\n",
    "Since $x$ and $y$ are uncorrelated, we may conclude that $\\Sigma_{x y} = \\Sigma_{y x} = 0$, and thus the convariance matrix should be defined as:\n",
    "\n",
    "$$  \n",
    "\\Sigma =  \\begin{bmatrix} var(x) & 0 \\\\ 0 & var(y) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### $x$ and $y$ are correlated\n",
    "\n",
    "Since $x$ and $y$ are positively correlated, we may conclude that $\\Sigma_{x y} > 0$, $\\Sigma_{y x} > 0$, and thus the convariance matrix should be defined as:\n",
    "\n",
    "$$  \n",
    "\\Sigma =  \\begin{bmatrix} var(x) & \\Sigma_{x y} \\\\ \\Sigma_{y x} & var(y) \\end{bmatrix}, \\Sigma_{x y} > 0, \\Sigma_{y x} > 0\n",
    "$$\n",
    "\n",
    "### $x$ and $y$ are anti-correlated\n",
    "\n",
    "Since $x$ and $y$ are negatively correlated, we may conclude that $\\Sigma_{x y} < 0$, $\\Sigma_{y x} < 0$, and thus the convariance matrix should be defined as:\n",
    "\n",
    "$$  \n",
    "\\Sigma =  \\begin{bmatrix} var(x) & \\Sigma_{x y} \\\\ \\Sigma_{y x} & var(y) \\end{bmatrix}, \\Sigma_{x y} < 0, \\Sigma_{y x} < 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute the principal axes for each of these distributions, i.e. the eigenvectors of the covariance matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression of eigenvector and eigenvalue is \n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "### $x$ and $y$ are uncorrelated\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} var(x) & 0 \\\\ 0 & var(y) \\end{bmatrix} \\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} var(x) & 0 \\\\ 0 & var(y) \\end{bmatrix} \\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} var(x) & 0 \\\\ 0 & var(y) \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} \\lambda v_1 \\\\ \\lambda v_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} var(x) v_1 \\\\ var(y) v_2 \\end{bmatrix}  = \\begin{bmatrix} \\lambda v_1 \\\\ \\lambda v_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therefore, if $var(x) \\neq var(y)$, we may conclude that the eigenvector does not exist. \n",
    "\n",
    "However, if $var(x) = var(y)$, which means $\\lambda = var(x) = var(y)$, then any vector would suffice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $x$ and $y$ are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps for positively correlated and negatively correlated $x$ and $y$ should be the same, since the only difference is the sign of the covariance, which is only represented in the actual calculations. \n",
    "\n",
    "$$  \n",
    "\\begin{bmatrix} var(x) & \\Sigma_{x y} \\\\ \\Sigma_{y x} & var(y) \\end{bmatrix}  \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} \\lambda v_1 \\\\ \\lambda v_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} var(x) v_1 + \\Sigma_{xy} v_2 \\\\ \\Sigma_{yx} v_1 + var(y) v_2 \\end{bmatrix}  = \\begin{bmatrix} \\lambda v_1 \\\\ \\lambda v_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{xy} v_2 = (\\lambda - var(x)v_1)v_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{yx}v_1 = (\\lambda - var(y) v_2)v_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{xy} v_2 = \\lambda v_1 - var(x)v_1^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_2 = \\frac{\\lambda v_1 - var(x)v_1^2}{\\Sigma_{xy}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_1 = \\frac{\\lambda v_2 - var(y)v_2^2}{\\Sigma_{yx}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_1 = \\frac{\\lambda \\frac{\\lambda v_1 - var(x)v_1^2}{\\Sigma_{xy}} - var(y)( \\frac{\\lambda v_1 - var(x)v_1^2}{\\Sigma_{xy}})^2}{\\Sigma_{yx}}\n",
    "$$\n",
    "\n",
    "After $v_1$ is solved, we just go back and solve for $v_2$. I will put a stop here since the process should be pretty trivial and in reality once we've gain the actual covariance matrix it should be pretty straight forward. \n",
    "\n",
    "The steps of solving for the eigenvalue $\\lambda$ should also be quite simple:\n",
    "\n",
    "$$\n",
    "\\Sigma - \\lambda I = \\begin{bmatrix} var(x) & \\Sigma_{x y} \\\\ \\Sigma_{y x} & var(y) \\end{bmatrix} - \\begin{bmatrix} \\lambda & 0 \\\\ 0  &  \\lambda  \\end{bmatrix} = \\begin{bmatrix} var(x) - \\lambda & \\Sigma_{xy} \\\\ \\Sigma_{yx} & var(y) - \\lambda  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Then we use the determinant to solve for the eigenvalue:\n",
    "\n",
    "$$\n",
    "var(x)var(y) + \\lambda ^2 - \\lambda var(x) - \\lambda var(y) = \\Sigma_{xy} \\Sigma_{yx}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\lambda ^2 - ( var(x) + var(y)) \\lambda - \\Sigma_{xy} \\Sigma_{yx} + var(x)var(y) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_1 = \\frac{var(x) + var(y) + \\sqrt{( var(x) - var(y))^2 - 4 \\Sigma_{xy} \\Sigma_{yx}}}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_2 = \\frac{var(x) + var(y) - \\sqrt{( var(x) - var(y))^2 - 4\\Sigma_{xy} \\Sigma_{yx}}}{2}\n",
    "$$\n",
    "\n",
    "All we should do next is to plug in the two eigenvalues, check which one is valid, and then solve for the corresponding eigenvector. Once again, I will pause my solution here since solving for the eigenvectors without any actual value is quite trivial, and as long as the steps I listed above are strictly followed, the calculation should be quite simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. Linear Gaussian Models (20 pts)\n",
    "\n",
    "Consider two multi-dimensional Gaussian random vector variables\n",
    "\n",
    "$$\n",
    "\\newcommand{\\bm}{\\mathbf}\n",
    "\\begin{eqnarray}\n",
    "p(\\bm{x}) &=& \\mathcal{N}(\\bm{x} | \\bm{\\mu_x}, \\bm{\\Sigma}_x) \\\\\n",
    "p(\\bm{z}) &=& \\mathcal{N}(\\bm{z} | \\bm{\\mu_z}, \\bm{\\Sigma}_z)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Now consider a third variable that is the sum of the first two:\n",
    "\n",
    "$$\n",
    "\\bm{y} = \\bm{x} + \\bm{z}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 What is the expression for the distribution $p(\\bm{y})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, assuming joint normality of $(\\mathbf{x}, \\mathbf{z})$, then we should have, according to the linear properties of multivariate normal random vectors,\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{z} = (\\mathbf{A} \\space \\space \\mathbf{B})  \\begin{pmatrix}\n",
    "    \\mathbf{x} \\\\  \\mathbf{z}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where both $\\mathbf{A}$ and $\\mathbf{B}$ are identity matrix $\\mathbf{I}$.\n",
    "\n",
    "And thus \n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}) = p(\\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{z}) =  \\mathcal{N} (\\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{y} | (\\mathbf{A} \\space \\space \\space  \\mathbf{B})  \\begin{pmatrix} \\mathbf{\\mu_x} \\\\ \\mathbf{\\mu_z} \\end{pmatrix}, (\\mathbf{A} \\space \\space \\space  \\mathbf{B}) \\mathbf{\\Sigma_{x, z} \\begin{pmatrix} \\mathbf{A^T} \\\\ \\mathbf{B^T} \\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "Then we shall plug in $\\mathbf{A} = \\mathbf{B} = \\mathbf{I}$, and the final expression of $p(\\mathbf{y})$ would be:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}) = \\mathcal{N} ( \\mathbf{x} + \\mathbf{z} | \\mathbf{\\mu_x} + \\mathbf{\\mu_z}, \\mathbf{ \\Sigma_{xx} } + \\mathbf{\\Sigma_{xz}^T} + \\mathbf{\\Sigma_{xz} } + \\mathbf{ \\Sigma_{zz}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 What is the expression for the condidtional distribution $p(\\bm{y|x})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Write code that simulates this data and illustrate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3. Dimensionality Reduction and PCA\n",
    "\n",
    "In this quesiton you will use principal component analysis to reduce the dimensionality of your data and analyze the results.\n",
    "\n",
    "##  3.1 Find a set of high dimensional data.  It should be continuous and have at least 6 dimensions, e.g. stats for sports teams, small sound segments or images patches also work.  Note that if the dimensionality of the data is too large, you might run into computational efficiency problems using standard methods.  Describe the data and illustrate it, if appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for this problem I will be using the breast cancer dataset retrieved from the UCI machine learning database (\"http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\"). Let's first import the data and briefly take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', \n",
    "    header = None, \n",
    "    sep = ',')\n",
    "\n",
    "df.columns=['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', \n",
    "            'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', \n",
    "            'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', \n",
    "            'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', \n",
    "            'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', \n",
    "            'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "            'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "\n",
    "## drops the empty line if exist\n",
    "df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "## split the dataset into data X and class labels y, the id number will be ignored\n",
    "X = df.iloc[:,2:31].values\n",
    "y = df.iloc[:,1].values\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there are 32 columns in the data, where the first column is the `id` number, the second column is the label or class `diagnosis` representing the diagnosis of the breast tissues, where `B` = benign, `M` = malignant. The rest of the columns are different continuously valued features as described by the column headers above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute the principal components of the data.  Plot a few of the largest eigenvectors and interpret them in terms of how there are modeling the structure of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
