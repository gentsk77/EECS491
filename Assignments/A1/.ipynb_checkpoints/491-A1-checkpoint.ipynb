{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 491 Assignment 1\n",
    "\n",
    "Due Fri Feb 1 before midnight. 100 points total. (Note: the new due date differs from the syllabus, so that you have a full two weeks.)\n",
    "\n",
    "### Submitting assignments to Canvas\n",
    "\n",
    "- For jupyter notebooks, submit the .ipynb file and a pdf export of the notebook.  Make sure the pdf represents the latest state of your notebook.  If your are not using notebooks, writeup your assignment using latex and submit a pdf with your code.  The writeup should include relevant code with description if it can fit on a page.  Do not include binaries or large data files.\n",
    "\n",
    "- Use the following format for filenames:\n",
    "  - `EECS491-A1-yourcaseid.ipynb`\n",
    "  - `EECS491-A1-yourcaseid.pdf`\n",
    "\n",
    "- If you have more than these two files, put all your files in a directory named `EECS491-A1-yourcaseid`. zip the directory and submit it with the name `EECS491-A1-yourcaseid.zip`.  Do not use other compression formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of questions below aren't specified in great detail and you may need to spend sometime making sense of the questions themselves, which you can do from the reads and other sources.  You also might need to fill in some blanks or make some assumptions.  The spirit behind this approach is explained in [The Problem with Problems](http://web.mit.edu/6.969/www/readings/mazur.pdf) by Eric Mazur, which I encourage everyone to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Basic probability (10 pts)\n",
    "\n",
    "1.1. Prove (5 pts)\n",
    "\\begin{equation}\n",
    "p(x,y|z) = p(x|z)p(y|x,z)\n",
    "\\end{equation}\n",
    "\n",
    "$$ p(x,y|z) = \\frac{p(x,y,z)}{p(z)} $$\n",
    "$$ p(y|x,z) = \\frac{p(x,y,z)}{p(x,z)} $$\n",
    "$$ p(x|z) = \\frac{p(x,z)}{p(z)} $$\n",
    "This equation is algebraically correct: \n",
    "$$ \\frac{p(x,y,z)}{p(z)} = \\frac{p(x,y,z)}{p(x,z)}\\frac{p(x,z)}{p(z)} $$\n",
    "Thus \n",
    "$$ p(x,y|z) = p(x|z)p(y|x,z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Prove (5 pts)\n",
    "\\begin{equation}\n",
    "p(x|y,z) = \\frac{p(y|x,z)p(x|z)}{p(y|z)}\n",
    "\\end{equation}\n",
    "\n",
    "$$ p(x|y,z) = \\frac{p(x,y,z)}{p(y,z)} $$\n",
    "$$ p(y|x,z) = \\frac{p(x,y,z)}{p(x,z)} $$\n",
    "$$ p(x|z) = \\frac{p(x,z)}{p(z)} $$\n",
    "$$ p(y|z) = \\frac{p(y,z)}{p(z)} $$\n",
    "This equation is algebraically correct:\n",
    "$$ \\frac{p(x,y,z)}{p(y,z)} = \\frac{p(x,y,z)}{p(x,z)}\\frac{p(x,z)}{p(z)}\\frac{p(z)}{p(y,z)} $$\n",
    "Thus\n",
    "$$ p(x|y,z) = p(y|x,z)p(x|z)\\frac{1}{p(y|z)} $$\n",
    "$$ p(x|y,z) = \\frac{p(y|x,z)p(x|z)}{p(y|z)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Independence (10 pts)\n",
    "\n",
    "2.1 Show that independence is not transitive, i.e. \n",
    "$a ⫫ b ∧ b ⫫ c ⇏ a ⫫ c$. Define a joint probability distribution $p(a,b,c)$ for which the previous expression holds and provide an interpretation. (5 pts)\n",
    "\n",
    "2.2 Show that conditional independence does not imply marginal independence, i.e. $a ⫫ b | c ⇏ a ⫫ b$. Again provide an example. (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Inspector Clouseau re-revisited (20 pts)\n",
    "\n",
    "3.1 Write a program to evaluate $p(B|K)$ in Example 1.3 in Barber. Write your code and choose your data representations so that it is easy to use it to solve the remaining questions. Show that it correctly computes the value in the example. (5 pts)\n",
    "\n",
    "3.2 Define a different distribution for $p(K|M,B)$.  Your new distribution should result in the outcome that $p(B|K)$ is either $<0.1$ or $>0.9$, i.e. reasonably strong evidence.  Use the original values of $p(B)$ and $p(M)$ from the example.  Provide (invent) a reasonble justification for the value of each entry in $p(K|M,B)$. (5 pts)\n",
    "\n",
    "3.3 Derive the equation for $p(M|K)$. (5 pts)\n",
    "\n",
    "3.4 Calculate it's value for both the original $p(K|M,B)$ and the one you defined yourself. Is it possible to provide a summary of the main factors that contributed to the value?  Why/Why not?  Explain. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = 0.6\n",
    "pm = 0.2\n",
    "pkgnbnm = 0.3\n",
    "pkgnbm = 0.2\n",
    "pkgbnm = 0.6\n",
    "pkgbm = 0.1\n",
    "pbgk = -1\n",
    "def calc_pbgk():\n",
    "    pbgk = (pb * (pkgbm*pm + pkgbnm*(1-pm))) / (pb*(pkgbm * pm + pkgbnm * (1-pm)) + (1-pb)*(pkgnbm*pm + pkgnbnm * (1-pm)))\n",
    "    print(pbgk)\n",
    "print (\"3.1  p(b|k)\")\n",
    "calc_pbgk() ## This is the answer for 3.1\n",
    "pkgnbnm = 0.1\n",
    "pkgnbm = 0.01\n",
    "pkgbnm = 0.9\n",
    "pkgbm = 0.7\n",
    "pbgk = -1\n",
    "print (\"\\n3.2  p(b|k) with new values\")\n",
    "calc_pbgk() ## This is the answer for 3.2\n",
    "pmgk = -1\n",
    "def calc_pmgk():\n",
    "    pmgk = (pm * (pkgbm*pb + pkgnbm*(1-pb))) / (pm*(pkgbm * pb + pkgnbm * (1-pb)) + (1-pm)*(pkgbnm* pb + pkgnbnm * (1-pb)))\n",
    "    print(pmgk) ## 3.3\n",
    "print (\"\\n3.3 Refer to code, function calc_pmgk and LATEX in question\")\n",
    "print (\"\\n3.4 p(b|m) with new values\")\n",
    "calc_pmgk() ## 3.4\n",
    "pkgnbnm = 0.3\n",
    "pkgnbm = 0.2\n",
    "pkgbnm = 0.6\n",
    "pkgbm = 0.1\n",
    "pmgk = -1\n",
    "print (\"\\n3.4 p(b|m) with original values\")\n",
    "calc_pmgk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Biased views (20 pts)\n",
    "\n",
    "4.1 Write a program that calculates the posterior distribution of the $\\theta$ (probability of heads) from the Binomial distribution given $y$ heads out of $n$ trials.  Feel to use a package where the necessary distributions are defined as primitives. (5 pts)\n",
    "\n",
    "4.2 Imagine three different views on the coin bias:\n",
    "- \"I believe strongly that the coin is biased to either mostly heads or mostly tails.\"\n",
    "- \"I believe strongly that the coin is unbiased\".\n",
    "- \"I don't know anything about the bias of the coin.\"\n",
    "\n",
    "Define and plot prior distributions that expresses each of these beliefs.  Provide a brief explanation. (5 pts)\n",
    "\n",
    "4.3 Perform Bernoulli trials where one of these views is correct.  Show how the posterior distribution of $\\theta$ changes for each view for $n=0, 1, 2, 5, 10, \\textrm{and} 100$.  Each view should have its own plot, with the plots of the posterior after different numbers of trials overlayed. (5 pts)\n",
    "\n",
    "4.4 Is it possible that each view will always arrive at an accurate estimate of $\\theta$?  How might you determine which view is most consistent with the data after $n$ trials? (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem is what allows us to go from our sampling and prior distributions to our posterior distribution. The posterior distribution is the $P(θ|X)$. Or in English, the probability of our parameters given our data. And if you think about it that is what we really want. We are typically given our data – from maybe a survey or web traffic – and we want to figure out what parameters are most likely given our data. So how do we get to this posterior distribution? Here comes some math (don’t worry it is not too bad):\n",
    "\n",
    "By definition, we know that (If you don’t believe me, check out this page for a refresher):\n",
    "\n",
    "$P(A|B) = \\dfrac{P(A,B)}{P(B)}$ Or in English, the probability of seeing A given B is the probability of seeing them both divided by the probability of B.\n",
    "$P(B|A) = \\dfrac{P(A,B)}{P(A)}$ Or in English, the probability of seeing B given A is the probability of seeing them both divided by the probability of A.\n",
    "You will notice that both of these values share the same numerator, so:\n",
    "\n",
    "$P(A,B) = P(A|B)*P(B)$\n",
    "$P(A,B) = P(A|B)*P(B)$\n",
    "Thus:\n",
    "\n",
    "$P(A|B)*P(B) = P(B|A)*P(A)$\n",
    "\n",
    "Which implies:\n",
    "\n",
    "$P(A|B) = \\dfrac{P(B|A)*P(A)}{P(B)}$\n",
    "\n",
    "And plug in $θ$ for $A$ and $X$ for $B$:\n",
    "\n",
    "$P(\\theta|X) = \\dfrac{P(X|\\theta)*P(\\theta)}{P(X)}$\n",
    "\n",
    "Nice! Now we can plug in some terminology we know:\n",
    "\n",
    "$Posterior = \\dfrac{likelihood * prior}{P(X)}$\n",
    "\n",
    "But what is the $P(X)?$ Or in English, the probability of our data? That sounds weird… Let’s go back to some math and use B and A again:\n",
    "\n",
    "We know that $P(B)=∑AP(A,B)$ (check out this page for a refresher)\n",
    "\n",
    "And from our definitions above, we know that:\n",
    "\n",
    "$P(A,B) = P(A|B)*P(A)$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$P(B) = \\sum_{A} P(A|B)*P(A)$\n",
    "\n",
    "Plug in our $θ$ and $X$:\n",
    "\n",
    "$P(X) = \\sum_{\\theta} P(\\theta|X)*P(\\theta)$\n",
    "\n",
    "Plug in our terminology:\n",
    "\n",
    "$P(X) = \\sum_{\\theta} likelihood * prior$\n",
    "\n",
    "Wow! Isn’t that awesome! But what do we mean by $∑θ$. This means to sum over all the values of our parameters. In our coin flip example, we defined 100 values for our parameter p, so we would have to calculated the likelihood * prior for each of these values and sum all those anwers. That is our denominator for Bayes Theorem. Thus our final answer for Bayes is:\n",
    "\n",
    "$Posterior = \\dfrac{likelihood * prior}{\\sum_{\\theta} likelihood * prior}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bern_post(n_params=100, n_sample=100, true_p=.8, prior_p=.5, n_prior=100):\n",
    "    params = np.linspace(0, 1, n_params)\n",
    "    sample = np.random.binomial(n=1, p=true_p, size=n_sample)\n",
    "    likelihood = np.array([np.product(st.bernoulli.pmf(sample, p)) for p in params])\n",
    "    #likelihood = likelihood / np.sum(likelihood)\n",
    "    prior_sample = np.random.binomial(n=1, p=prior_p, size=n_prior)\n",
    "    prior = np.array([np.product(st.bernoulli.pmf(prior_sample, p)) for p in params])\n",
    "    prior = prior / np.sum(prior)\n",
    "    posterior = [prior[i] * likelihood[i] for i in range(prior.shape[0])]\n",
    "    posterior = posterior / np.sum(posterior)\n",
    "     \n",
    "    fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8,8))\n",
    "    axes[0].plot(params, likelihood)\n",
    "    axes[0].set_title(\"Sampling Distribution\")\n",
    "    axes[1].plot(params, prior)\n",
    "    axes[1].set_title(\"Prior Distribution\")\n",
    "    axes[2].plot(params, posterior)\n",
    "    axes[2].set_title(\"Posterior Distribution\")\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "     \n",
    "    return posterior\n",
    "\n",
    "example_post = bern_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Inference using the Poisson distribution (20 pts)\n",
    "\n",
    "Suppose you are observing a series of events that occur at the following times (in seconds): 0.53, 0.65, 0.91, 1.19, 1.30, 1.33, 1.90, 2.01, 2.48.\n",
    "\n",
    "5.1 Model the rate at which the events are produced using a Poisson distribution where $\\lambda$ is the number of events $n$ observed per unit time (1 second).  Show the likelihood equation and plot it for three different values of $\\lambda$: less, about equal, and greater than what you estimate (intuitively) from the data. (5 pts)\n",
    "\n",
    "5.2 Derive the posterior distribution of $\\lambda$ assuming a Gamma prior (usually defined with parameters $\\alpha$ and $\\beta$).  The posterior should have the form $p(\\lambda | n, T, \\alpha, \\beta)$ where $T$ is the total duration of the observation period and $n$ is the number of events observed within that period. (5 pts)\n",
    "\n",
    "5.3 Show that the Gamma distribution is a *conjugate prior* for the Poisson distribution, i.e. it is also a Gamma distribution, but defined by parameters $\\alpha'$ and $\\beta'$ that are functions of the prior and likelihood parameters. (5 pts)\n",
    "\n",
    "5.4 Plot the posterior distribution for the data above at times $T$ = 0, 0.5, and 1.5.  Overlay the curves on a single plot.  Comment how it is possible for your beliefs to change even though no new events have been observed. (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Exploration (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these problems, you are meant to do creative exploration.  Define and explore a:\n",
    "\n",
    "6.1 discrete inference problem (10 pts)\n",
    "\n",
    "6.2 continuous inference problem (10 pts)\n",
    "\n",
    "This is meant to be open-ended; you should feel the need to write a book chapter; but neither should you just change the numbers in one of the problems above.  After doing the readings and problems above, you should pick a concept you want to understand better or an simple modeling idea you want to try out.  The general idea is for you to teaching yourself (and potentially a classate) about something.  You don't necessarily have to know what that is when you start, but you should be able to express what you learned.\n",
    "\n",
    "Here is the grading rubric:\n",
    "- Were the problem clearly described and concise? (3 pts)\n",
    "- Were the relevant concepts clearly explained? (3 pts)\n",
    "- Did the problem go beyond or is distinct from what was already convered in the questions above? (4 pts)\n",
    "\n",
    "You can use the readings and other sources for inspiration, but here are a few ideas:\n",
    "- An inference problem using categorical data\n",
    "- A disease for which there are two different tests\n",
    "- A two-dimensional continuous inference problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
