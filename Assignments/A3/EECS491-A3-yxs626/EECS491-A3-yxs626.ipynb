{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 491 Assignment 3\n",
    "\n",
    "  Yue Shu  \n",
    "  Spring 2019  \n",
    "  Prof. Lewicki  \n",
    "  \n",
    "\n",
    "**IMPORTANT: all image results I had for my last update are stored under the folder `Images`, and all images I load in the Jupyter Notebook are also under that image direcotry. However, images generated by the code will be directly restored in the `Outputs` folder, where I left no image right now just for you to initialize.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1. MRFs and Images Denoising\n",
    "\n",
    "In this problem, you will implement the image de-noising example using a Markov Random Field (MRF).  This material on MRFs is covered in the textbook (Barber) in chapter 4.2.5. The lecture and this problem is based on the presentation in Bishop in chapter 8.3, which is available online.\n",
    "\n",
    "As discussed in class, energy function for this MRF is\n",
    "\n",
    "$$ E(\\mathbf{x}, \\mathbf{y}) = h \\sum_i x_i - \\beta \\sum_{i,j} x_i x_j - \\eta \\sum_i x_i y_i $$\n",
    "\n",
    "where the binary variables $x_i$ represent the unknown, noise-free image pixels, which are binary, i.e. black or white.  The variables $y_i$ represent the observed noisy pixels, i.e. the pixel could randomly change from black ($=-1$) to white ($=+1$) or vice-versa.  \n",
    "\n",
    "The corresponding joint probability distribution over the variables is\n",
    "\n",
    "$$ p(\\mathbf{x},\\mathbf{y}) = \\frac{1}{Z} \\exp \\left[ -E(\\mathbf{x},\\mathbf{y}) \\right] $$\n",
    "\n",
    "## 1.1 Derive the equation that specifies the change in the energy equation when one variable changes state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started with the original energy function equation $E$, we have: \n",
    "\n",
    "$$ E(\\mathbf{x}, \\mathbf{y}) = h \\sum_i x_i - \\beta \\sum_{i,j} x_i x_j - \\eta \\sum_i x_i y_i $$\n",
    "\n",
    "  Now let $x_k'$ denote the state of $x_k$ after changing, and $E'$ denotes the new energy equation.\n",
    "  Since each pixel of the image we're discussing here is a binary variable, we may simply assume that the change of one variable is either from $+1$ to $-1$ or vice-versa. By flipping the state of $x_i$, we simply flip by sign and thus obtain $x_i' = -x_i$.\n",
    "\n",
    "  Therefore, to calculate the difference in the energy equation, we simply substract $E$ from $E'$ as below:\n",
    "\n",
    "  $$ E' - E =    E(\\mathbf{x}', \\mathbf{y}) -   E(\\mathbf{x}, \\mathbf{y}) $$ \n",
    "  $$ =  h * (x_0 + ... + x_k' + ... + x_n) - \\beta * (x_0x_1 + ... + x_0x_k' + ... + x_0x_n + ... + x_k'x_0 + ... + x_k'x_n + ... $$\n",
    "  $$ + x_nx_0 + ... + x_nx_k' + ... + x_nx_{n-1}) - \\eta * (x_0y_0 + ... + x_k'y_k + ... + x_ny_n) $$\n",
    "  $$ - (h * (x_0 + ... + x_k + ... + x_n) - \\beta * (x_0x_1 + ... + x_0x_k + ... + x_0x_n + ... + x_kx_0 + ... + x_kx_n + ... $$\n",
    "  $$ + x_nx_0 + ... + x_nx_k + ... + x_nx_{n-1}) - \\eta * (x_0y_0 + ... + x_ky_k + ... + x_ny_n)) $$\n",
    "  $$ = h * (x_0 + ... - x_k + ... + x_n) - \\beta * (x_0x_1 + ... - x_0x_k + ... + x_0x_n + ... - x_kx_0 + ... - x_kx_n + ... $$\n",
    "  $$ + x_nx_0 + ... - x_nx_k + ... + x_nx_{n-1}) - \\eta * (x_0y_0 + ... - x_ky_k + ... + x_ny_n) $$\n",
    "  $$ - (h * (x_0 + ... + x_k + ... + x_n) - \\beta * (x_0x_1 + ... + x_0x_k + ... + x_0x_n + ... + x_kx_0 + ... + x_kx_n + ... $$\n",
    "  $$ + x_nx_0 + ... + x_nx_k + ... + x_nx_{n-1}) - \\eta * (x_0y_0 + ... + x_ky_k + ... + x_ny_n)) $$\n",
    "  $$ E' - E = -2hx_k + 2\\beta (2 \\sum_{j \\in nbr(k)} x_j x_k) + 2 \\eta x_k y_k = -2hx_k + 4\\beta \\sum_{j \\in nbr(k)} x_j x_k + 2 \\eta x_k y_k\n",
    "  $$\n",
    "\n",
    "And the final equation $E' - E$ that specifies the change in the energy equation when one variable $x_k$ changes state is:\n",
    "\n",
    "$$ E' - E = -2hx_k + 4\\beta \\sum_{j \\in nbr(k)} x_j x_k + 2 \\eta x_k y_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Write a program to iteratively (or in random order) update the state variables to minimize the energy (maximize the probability).  Explain your code.  Show that the update algorithm minimizes the energy $E(\\mathbf{x}, \\mathbf{y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's define the function to calculate the energy difference. For future convenience, I make the output of the function an array that can also tell me the index `k` of the pixel under changing. \n",
    "\n",
    "  `pixels`: an array indicating the pixel of our image  \n",
    "  `nbr`: an array indicating $x_j$  \n",
    "  `k`: the index of $x_k$  \n",
    "  `yk`: the original observation of $x_k$  \n",
    "  `h`, `beta`, `eta`: the parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all packages used in this assignment\n",
    "\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import graphviz \n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_diff (pixels, nbr, k, yk, h, beta, eta):\n",
    "    output = [0, k]\n",
    "    sum_xjxk = 0\n",
    "    i = 0\n",
    "    ## calculating the sum of all xjxk\n",
    "    for xj in nbr:\n",
    "        sum_xjxk += xj * pixels[k]\n",
    "        i+= 1\n",
    "    output[0] += - 2 * h * pixels[k] + 4 * beta * sum_xjxk + 2 * eta * pixels[k] * yk\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a helper method to retrieve the neighbours of the pixel we are trying to flip. To eliminate unnecessary edge cases, we may just assume the smallest size of the image is 3x3.\n",
    "\n",
    "  `width`: the width of the input image  \n",
    "  `height`: the height of the input image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nbr (pixels, k, width, height):\n",
    "    ## the height of k in 2D matrix\n",
    "    i = int(k / width)\n",
    "    ## the width of k in 2D matrix\n",
    "    j = int(k % width)\n",
    "    ## corners\n",
    "    if i == 0 and j == 0:\n",
    "        return [pixels[k + 1], pixels[width]]\n",
    "    elif i == 0 and j == width - 1:\n",
    "        return [pixels[k - 1], pixels[k + width]]\n",
    "    elif i == height - 1 and j == 0:\n",
    "        return [pixels[k + 1], pixels[k - width]]\n",
    "    elif i == height - 1 and j == width - 1:\n",
    "        return [pixels[k - 1], pixels[k - width]]\n",
    "    ## edges\n",
    "    elif i == 0:\n",
    "        return [pixels[k + width], pixels[k + 1], pixels[k - 1]]\n",
    "    elif i == height - 1:\n",
    "        return [pixels[k - width], pixels[k + 1], pixels[k - 1]]\n",
    "    elif j == 0:\n",
    "        return [pixels[k + 1], pixels[k + width], pixels[k - width]]\n",
    "    elif j == width - 1:\n",
    "        return [pixels[k - 1], pixels[k + width], pixels[k - width]]\n",
    "    # body\n",
    "    else:\n",
    "        return [pixels[k + 1], pixels[k - 1], pixels[k + width], pixels[k - width]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and setup our algorithm. \n",
    "\n",
    "  I'll implement with a simplified version of simulated annealing algorithm we covered in EECS391, with our energy difference function as the heuristic.   \n",
    "  So when the energy difference is negative, which means the energy is decreasing, we just accept the result and keep descenting; when the energy difference is positive, we accept the result with a probability less than 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a helper to determine the probability of acceptance\n",
    "def accept (delta, T):\n",
    "    ## catch overflow error\n",
    "    try:\n",
    "        return math.exp( - delta / T)\n",
    "    except OverflowError:\n",
    "        return 0\n",
    "\n",
    "## simulated annealing algorithm\n",
    "def anneal(pix, dim, param_anneal, param_energy):\n",
    "    \n",
    "    ## setting up the parameters\n",
    "    T = param_anneal[0]\n",
    "    T_min = param_anneal[1]\n",
    "    alpha = param_anneal[2]\n",
    "    \n",
    "    h = param_energy[0]\n",
    "    beta = param_energy[1]\n",
    "    eta = param_energy[2]\n",
    "    \n",
    "    width = dim[0]\n",
    "    height = dim[1]\n",
    "    \n",
    "    ## the result we want\n",
    "    output = pix[:]\n",
    "    \n",
    "    ## continue annealing as long as the temperature is higher than the terminate value\n",
    "    while T > T_min:\n",
    "        for i in range(50):\n",
    "            ## randomly pick an index k from the pixels\n",
    "            k = random.randint(0, len(output) - 1)\n",
    "            ## retrieve the neighbours of k\n",
    "            nbr = get_nbr(output, k, width, height)\n",
    "            diff = energy_diff(output, nbr, k, pix[k], h, beta, eta)\n",
    "            if diff[0] < 0:\n",
    "                output[k] = 0 - output[k]\n",
    "            else:\n",
    "                ap = accept(diff[0], T)\n",
    "                if ap > random.random():\n",
    "                    output[k] = 0 - output[k]\n",
    "        T = T * alpha\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's have a wrapper method to also compute the finalized energy $E(\\mathbf{x}, \\mathbf{y})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __MRF_denoise__ (pixels, dim, param_anneal, param_energy):\n",
    "    \n",
    "    pix = pixels[:]\n",
    "    ## take the output of simulated annealing\n",
    "    output = anneal(pix, dim, param_anneal, param_energy)\n",
    "    \n",
    "    ## setup parameters\n",
    "    h = param_energy[0]\n",
    "    beta = param_energy[1]\n",
    "    eta = param_energy[2]\n",
    "    \n",
    "    width = dim[0]\n",
    "    height = dim[1]\n",
    "    \n",
    "    ## the sum variables we need for computing the energy equation\n",
    "    sum_xi = 0\n",
    "    sum_xixj = 0\n",
    "    sum_xiyi = 0\n",
    "    \n",
    "    ## compute sum of xi\n",
    "    for xi in output:\n",
    "        sum_xi += xi\n",
    "    \n",
    "    ## compute sum of xiyi\n",
    "    i = 0\n",
    "    for xi in output:\n",
    "        sum_xiyi += xi * (pixels[i])\n",
    "        i += 1\n",
    "    \n",
    "    ## compute sum of xixj\n",
    "    i = 0\n",
    "    for xi in output: \n",
    "        for xj in get_nbr(output, i, width, height):\n",
    "            sum_xixj += xi * xj\n",
    "        i += 1\n",
    "    \n",
    "    return h * sum_xi - beta * sum_xixj - eta * sum_xiyi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  According to simulated annealing algorithm, if given appropriate heuristic, the final energy we get should always end at the global optimal, aka the min energy.  \n",
    "  However, there does exist some uncertainty in real life practice, where there is no guarantee to always get the most optimal answer. We can first have a really simple example to test our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_anneal = [1, 0.001, 0.999]\n",
    "param_energy = [0, 1, 2.1]\n",
    "## assuming the noise is around 10%, and this is supposed to be a very simplified 3x3 all-black image \n",
    "pix = [-1,-1,-1,1,-1,-1,-1,-1,-1]\n",
    "anneal(pix, [3, 3], param_anneal, param_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-38.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__MRF_denoise__(pix, [3,3], param_anneal, param_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  According to the output above, we can see that the final output in this case is just the local minimum.  \n",
    "  Feel free to try the output, it should return the same results each time. We can practice on some more complexed images in the next part.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Illustrate the model by plot of the image as it is being de-noised at the beginning, middle, and end of the updating.  Choose images that aren't too high resolution so that the individual pixels are visible as squaures.  You may also do a live plot in a notebook to show it updating continuously, but make sure you have the static plots too in case the dynamic plot has portability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this part, I will be using the a txt file `pepe.txt` as the input pixels. The image was found online and converted to binary pixels via https://www.dcode.fr/binary-image. The original text file has all `black` pixels as `0` and `white` pixels `1`. We may change that to what we need later on. \n",
    "\n",
    "Let's start with importing the pixel and inspect the original good pepe image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the primitive pixel file as a whole string to obtain length\n",
    "with open(\"pepe.txt\") as t:\n",
    "    text = t.read()\n",
    "    \n",
    "## the dimensions of the image\n",
    "width = 0\n",
    "height = 0\n",
    "pixels = []\n",
    "\n",
    "## import the pixel as 1D array\n",
    "with open(\"pepe.txt\") as txt:\n",
    "    for char in range(len(text)):\n",
    "        letter = txt.read(1)\n",
    "        if letter.isdigit():\n",
    "            pixels.append(int(letter))\n",
    "        elif letter == '\\n':\n",
    "            height += 1\n",
    "\n",
    "pixels = array(pixels)\n",
    "width = int(len(pixels) / height)\n",
    "\n",
    "## create image with Pillow\n",
    "img = Image.new('1', (width, height))\n",
    "pixel = img.load()\n",
    "\n",
    "## pass pixels in the 1D array over the pixel of the image\n",
    "index = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        pixel[j, i] = int(pixels[index])\n",
    "        index += 1\n",
    "        \n",
    "img.save('Outputs/goodpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![original pepe image](Images/goodpepe.png)\n",
    "Alright, now we have our original good pepe. The next step is to read from the image and do the denoising. We want to arbitrarily flip some bits to make sure we have the \"noises\" in the image. Suppose we are having a noise rate of at most 10% of total pixels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Our good pepe\n",
    "pic = Image.open('Outputs/goodpepe.png')\n",
    "## make sure this is a binary image\n",
    "print(pic.mode)\n",
    "pix = pic.load()\n",
    "\n",
    "## the observed pixel array with noises\n",
    "observe = []\n",
    "## total number of noises allowed, in this case is 0.1 * total pixels \n",
    "max_noises = int(0.1 * len(pixels))\n",
    "## index of noise pixels\n",
    "noise = []\n",
    "\n",
    "## first append the pixels as usual\n",
    "index = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        ## to make sure we have +1 for whites and -1 for blacks\n",
    "        observe.append(int(pix[j, i] / 255) * 2 - 1)\n",
    "        \n",
    "## we allow repeated indices in this case, since the noise won't always be exactly 10% in real life\n",
    "for i in range(max_noises):\n",
    "    noise.append(random.randint(0, len(pixels) - 1))\n",
    "      \n",
    "## flip the bits!\n",
    "for pix in noise:\n",
    "    observe[pix] = 0 - observe[pix]\n",
    "    \n",
    "observe = array(observe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look the image with noises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create image with Pillow\n",
    "badimg = Image.new('1', (width, height))\n",
    "badpixel = badimg.load()\n",
    "\n",
    "## pass pixels in the 1D array over the pixel of the image\n",
    "index = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        badpixel[j, i] = int(observe[index])\n",
    "        index += 1\n",
    "        \n",
    "badimg.save('Outputs/badpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noisy pepe image](Images/badpepe.png)\n",
    "\n",
    "Awesome, we have the ugly pepe as expected. Don't feel bad about pepe, let's take a look at how our MRF denoising algorithm can change the situation.\n",
    "\n",
    "To make sure we can also see the image in the middle of the updating, let's first make a few modification on our MRF method from the previous part. What we will do is to break the simulated annealing to two steps, from the original temperature to the half, take a look at the result, and then continue to go from the half to the min temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_denoise (pixels, dim, param_anneal, param_energy, imgname):\n",
    "    \n",
    "    pixels = pixels[:]\n",
    "    \n",
    "    width = dim[0]\n",
    "    height = dim[1]\n",
    "    \n",
    "    output = anneal(pixels, dim, param_anneal, param_energy)\n",
    "    \n",
    "    ## create image with Pillow\n",
    "    betterimg = Image.new('1', (width, height))\n",
    "    betterpixel = betterimg.load()\n",
    "\n",
    "    ## pass pixels in the 1D array over the pixel of the image\n",
    "    index = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            betterpixel[j, i] = int(output[index])\n",
    "            index += 1\n",
    "        \n",
    "    betterimg.save(imgname)\n",
    "    \n",
    "    ## setup parameters\n",
    "    h = param_energy[0]\n",
    "    beta = param_energy[1]\n",
    "    eta = param_energy[2]\n",
    "\n",
    "    ## the sum variables we need for computing the energy equation\n",
    "    sum_xi = 0\n",
    "    sum_xixj = 0\n",
    "    sum_xiyi = 0\n",
    "    \n",
    "    ## compute sum of xi\n",
    "    for xi in output:\n",
    "        sum_xi += xi\n",
    "    \n",
    "    ## compute sum of xiyi\n",
    "    i = 0\n",
    "    for xi in output:\n",
    "        sum_xiyi += xi * (pixels[i])\n",
    "        i += 1\n",
    "    \n",
    "    ## compute sum of xixj\n",
    "    i = 0\n",
    "    for xi in output: \n",
    "        for xj in get_nbr(output, i, width, height):\n",
    "            sum_xixj += xi * xj\n",
    "        i += 1\n",
    "    \n",
    "    ## compute the energy function\n",
    "    result =  h * sum_xi - beta * sum_xixj - eta * sum_xiyi\n",
    "    print('The final energy is: ') \n",
    "    print(result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimpepe = [width, height]\n",
    "param_anneal = [1, 0.001, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-29220.0\n"
     ]
    }
   ],
   "source": [
    "param_first = [1, (1 + 0.01) / 2, 0.99]\n",
    "param_energy = [0, 1, 2.1]\n",
    "## Half of the updating\n",
    "betterpixel = show_denoise(observe, dimpepe, param_first, param_energy, 'Outputs/betterpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our pepe half way through the updating:\n",
    "![better pepe image](Images/betterpepe.png)\n",
    "\n",
    "At least it looks better isn't it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-33016.0\n"
     ]
    }
   ],
   "source": [
    "param_second = [(1 + 0.01) / 2, 0.01, 0.99]\n",
    "## Updating completely done\n",
    "newpixel = show_denoise(betterpixel, dimpepe, param_second, param_energy, 'Outputs/sadpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sad pepe image](Images/sadpepe.png)\n",
    "Finally we have the pepe after the whole updating. Actually I'm not sure if it's just me or the pepe really seems sader than the original image. \n",
    "\n",
    "Anyways, our algorithm works, and that's the most important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Experiment with different settings of the energy equation parameters and explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the energy equation, $\\eta$ is a positive constant to determine how happy we are to allow difference with original observation, $\\beta$ is a positive constant to determine the tendency of neighbouring pixels to be the same, and $h$ is a positive constant to determine the tendency that the pixels are black/white. \n",
    "\n",
    "For my previous section, I used the regular $(\\eta = 2.1, \\beta = 1.0, h = 0)$ parameter as suggested in Bishop. Here let's try out a few more possibilities. \n",
    "\n",
    "*NOTICE: maybe it is due to the synchronization of Jupyter Notebook, sometimes the output results from the following cases get affected by previously tested cases. Therefore, to test the authenticity of each case, please shut down the notebook, do not restart the entire notebook, start from the energy difference cell, and run each case individually. I repeat, DO NOT restart the notebook and run all cells!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case One: Higher $\\beta$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-54512.0\n"
     ]
    }
   ],
   "source": [
    "param_energy1 = [0, 2, 2.1]\n",
    "\n",
    "s1 = show_denoise(observe, dimpepe, param_anneal, param_energy1, 'Outputs/exp1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pepe with larger beta](Images/exp1.png)\n",
    "\n",
    "Just as we predicted, larger $\\beta$ value increase the tendency to infer higher similarity between neighbouring pixels, and in this case we have a pepe with no freckle at all. However, the problem is that we can also lose many details by allowing a $\\beta$ value that is too large. In this case the value is fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Two: Higher $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-33142.0\n"
     ]
    }
   ],
   "source": [
    "param_energy2 = [0.2, 1, 2.1]\n",
    "\n",
    "s2 = show_denoise(observe, dimpepe, param_anneal, param_energy2, 'Outputs/exp2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pepe with larger beta](Images/exp2.png)\n",
    "In this case the result is a little bit similar to what we have in the previous case, since by allowing a higher $h$, the occurence of noises is also undermined by the promotion of white color instead of the black. In this way, black noises are more likely to be eliminated in first place, and then white noises in the black are those left to be descented since they are surrounded by neigboured black pixels. Therefore the image also provides better consistency, but less details, which is more like large color lumps piled together...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Three: Higher $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-55776\n"
     ]
    }
   ],
   "source": [
    "param_energy3 = [0, 1, 6]\n",
    "\n",
    "s3 = show_denoise(observe, dimpepe, param_anneal, param_energy3, 'Outputs/exp3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pepe with larger eta](Images/exp3.png)\n",
    "This time the output looks quite different from what we have for the previous two cases, since a higher $\\\\eta$, given everything else unchanged, indicates that we are more happy with changing from the original observation, which can potentially have new noises that are different from the noises we had originally. Still, a great part of the scattered noises are eliminated since we promote changing, and the detail of the image is not undermined so bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Four: $\\beta = 0$\n",
    "\n",
    "In Bishop we covered the case if $\\beta = 0$ will just produce the originial solution or a very similar one since it is not willing to change if not stimulated by neighbouring differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "-12096.0\n"
     ]
    }
   ],
   "source": [
    "param_energy4 = [0, 0, 2.1]\n",
    "s4 = show_denoise(observe, dimpepe, param_anneal, param_energy4, 'Outputs/exp4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pepe with zero beta](Images/exp4.png)\n",
    "We may confirm with our result over here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Generalize the energy equation so that the model considers more than just pairs of pixels.  Explain your rationale behind this new model. Illustrate it with denoising examples (other types of images) that are not well-handled by the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the major problem with the model we have right now is that it only supports binary pixel inputs, which is very rare in real life. Even the binary image provided by Pillow has more continuous value than $1$ and $-1$, which would force us to have a harder threshold. \n",
    "\n",
    "Therefore, let's try to have grey-scaled images also supported by our algorithm by having more continuously valued inputs. \n",
    "\n",
    "As usual, let's start with having the new energy function setup. To support greyscaled images, the function should be able to identify continuous differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using 8-bits greyscale with the Pillow library, our algorithm only need to support one value indicating the pixel color ranging from 0 to 255, the larger the value the \"whiter\" the pixel. Therefore, in order to still determine the difference, we can simply solve for the value of $|x_i - x_j|^2$ as well as $|x_i - y_i|^2$ as a replacement of $x_ix_j$ and $x_iy_i$ in the original equation. Furthermore, since we are doing the gradient descent, which means lower $E$ is desirable, we should flip the sign from minus to plus so as smaller values following the sign are better. \n",
    "\n",
    "So the new energy equation $E(\\mathbf{x}, \\mathbf{y})$ will be:\n",
    "\n",
    "$$ \n",
    " E(\\mathbf{x}, \\mathbf{y}) = h \\sum_i x_i + \\beta \\sum_{i, j} |x_i - x_j|^2 + \\eta \\sum_i |x_i - y_i|^2\n",
    "$$\n",
    "And deriving from the above equation we shall obtain the difference function as our heuristic again: \n",
    "$$\n",
    "E' - E = h(x_k' - x_k) + 2 \\beta \\sum_{j \\in nbr(k)} (|x_k' - x_j|^2 - |x_k - x_j|^2) + \\eta (|x_k' - y_k|^2 - |x_k - y_k|^2)\n",
    "$$\n",
    "\n",
    "Now we may implement the difference function for greyscale input images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we maintain most of the same input parameters as we did for the previous one\n",
    "## since the basic structure is not changed, except for this time we also need the updated xk value: xl\n",
    "def grey_energy_diff (pixels, nbr, k, xl, yk, h, beta, eta):\n",
    "    output = [0, k]\n",
    "    a = h * (xl - pixels[k])\n",
    "    b = 0\n",
    "    c = eta * (abs(xl - yk) ** 2 - abs(pixels[k] - yk) ** 2)\n",
    "    \n",
    "    for xj in nbr:\n",
    "        b += abs(xl - xj) ** 2 - abs(pixels[k] - xj) ** 2\n",
    "    output[0] += a + 2 * beta * b + eta * c\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulated annealing algorithm also needs to be generalized since the way we change the value is rather different now. Instead of flipping the value from -1 to 1 or vice versa, now we will generate a new value ranging from 0 to 1 according to an algorithm specified in the code below (I will map 8 bits pixels to continuous value ranging from $[0, 1]$ later on to avoid too many overflow errors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a helper to determine the probability of acceptance\n",
    "def gaccept (delta, T):\n",
    "    ## prevent math overflow\n",
    "    try:\n",
    "        return math.exp(- delta / T)\n",
    "    except OverflowError:\n",
    "        return 0\n",
    "    \n",
    "## simulated annealing algorithm for greyscaled input images\n",
    "def grey_anneal(pixels, dim, param_anneal, param_energy):\n",
    "    \n",
    "    ## setting up the parameters\n",
    "    T = param_anneal[0]\n",
    "    T_min = param_anneal[1]\n",
    "    alpha = param_anneal[2]\n",
    "    \n",
    "    h = param_energy[0]\n",
    "    beta = param_energy[1]\n",
    "    eta = param_energy[2]\n",
    "    \n",
    "    width = dim[0]\n",
    "    height = dim[1]\n",
    "    \n",
    "    ## the result we want\n",
    "    output = pixels[:]\n",
    "    \n",
    "    ## continue annealing as long as the temperature is higher than the terminate value\n",
    "    while T > T_min:\n",
    "        ## allow more iterations to increase accuracy\n",
    "        for i in range(500):\n",
    "            ## randomly pick an index k from the pixels\n",
    "            k = random.randint(0, len(output) - 1)\n",
    "            ## retrieve the neighbours of k\n",
    "            nbr = get_nbr(output, k, width, height)\n",
    "            ## the updating value of xk will just be the median of its neighbours\n",
    "            xl = median(nbr)\n",
    "            diff = grey_energy_diff(output, nbr, k, xl, pixels[k], h, beta, eta)\n",
    "            ## accept given negative difference \n",
    "            if diff[0] < 0:\n",
    "                output[k] = xl\n",
    "            ## accept with a probability given positive difference\n",
    "            ap = gaccept(diff[0], T)\n",
    "            if ap > random.random():\n",
    "                output[k] = xl\n",
    "        T = T * alpha\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  And right now we might go on and do the setup for our greyscaled image.  \n",
    "  I will still use the pepe this time since I'm in the mood.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "## Our grey pepe\n",
    "gpic = Image.open('Images/greypepe.png').convert('L')\n",
    "gpic.save('Outputs/gpepe.png')\n",
    "## make sure this is an 8-bit greyscaled image\n",
    "print(gpic.mode)\n",
    "gpix = gpic.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grey pepe](Images/gpepe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as last time, we still need to convert the pixel matrix to a 1D array, and we will convert the 8-bits values to floating numbers from $[0, 1]$ as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "## the dimensions of the image\n",
    "gwidth = gpic.size[0]\n",
    "gheight = gpic.size[1]\n",
    "gpixels = []\n",
    "\n",
    "## convert the pixels to 1D array\n",
    "for i in range(gheight):\n",
    "    for j in range(gwidth):\n",
    "        ## simplify 8-bit pixels\n",
    "        gpixels.append(gpix[j, i] / 255)\n",
    "\n",
    "gpixels = array(gpixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test our results, I will randomly add noises that will not exceed 10% of the total pixels as last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize the observation as a pixel array without noises\n",
    "gobserve = gpixels[:]\n",
    "## total number of noises allowed, in this case is 0.1 * total pixels \n",
    "gmax_noises = int(0.1 * len(gpixels))\n",
    "## index of noise pixels\n",
    "gnoise = []\n",
    "\n",
    "## we allow repeated indices in this case, since the noise won't always be exactly 10% in real life\n",
    "for i in range(gmax_noises):\n",
    "    gnoise.append(random.randint(0, len(gpixels) - 1))\n",
    "    \n",
    "## generate random values as noises\n",
    "for pix in gnoise:\n",
    "    gobserve[pix] = random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look the image with noises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbadimg = Image.new('L', (gwidth, gheight))\n",
    "gbadpixel = gbadimg.load()\n",
    "\n",
    "## pass pixels in the 1D array over the pixel of the image\n",
    "index = 0\n",
    "for i in range(gheight):\n",
    "    for j in range(gwidth):\n",
    "        ## we still need to convert back to normal values\n",
    "        gbadpixel[j, i] = int(gobserve[index] * 255)\n",
    "        index += 1\n",
    "        \n",
    "gbadimg.save('Outputs/gbadpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bad grey pepe](Images/gbadpepe.png)\n",
    "\n",
    "So once again, we are having this noisy ugly grey pepe. Let's take a look at how our updated algorithm can save this poor little frog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grey_show_denoise (pixels, dim, param_anneal, param_energy, imgname):\n",
    "    \n",
    "    ## dimensions of the image\n",
    "    width = dim[0]\n",
    "    height = dim[1]\n",
    "    \n",
    "    ## the denoised image pixel output\n",
    "    output = grey_anneal(gobserve, dim, param_anneal, param_energy)\n",
    "    \n",
    "    betterimg = Image.new('L', (width, height))\n",
    "    betterpixel = betterimg.load()\n",
    "\n",
    "    ## pass pixels in the 1D array over the pixel of the image\n",
    "    index = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            ## we still need to convert back to normal values\n",
    "            betterpixel[j, i] = int(output[index] * 255)\n",
    "            index += 1\n",
    "        \n",
    "    betterimg.save(imgname)\n",
    "    \n",
    "    ## setup parameters\n",
    "    h = param_energy[0]\n",
    "    beta = param_energy[1]\n",
    "    eta = param_energy[2]\n",
    "\n",
    "    ## the sum variables we need for computing the energy equation\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    ## compute sum of xi\n",
    "    for xi in output:\n",
    "        a += xi\n",
    "    \n",
    "    ## compute sum of |xi - yi|^2\n",
    "    i = 0\n",
    "    for xi in output:\n",
    "        c += abs(xi - pixels[i])\n",
    "        i += 1\n",
    "    \n",
    "    ## compute sum of |xi - xj|^2\n",
    "    i = 0\n",
    "    for xi in output: \n",
    "        for xj in get_nbr(output, i, width, height):\n",
    "            b += abs(xi - xj)\n",
    "        i += 1\n",
    "    \n",
    "    result =  h * a + beta * b + eta * c\n",
    "    print('The final energy is: ')  \n",
    "    print(result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimg = [gwidth, gheight]\n",
    "param_anneal = [1, 0.001, 0.999]\n",
    "param_energy = [0, 10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final energy is: \n",
      "19213.75652782905\n"
     ]
    }
   ],
   "source": [
    "o1 = grey_show_denoise(gobserve, dimg, param_anneal, param_energy, 'Outputs/gsadpepe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grey sad pepe](Images/gsadpepe.png)\n",
    "\n",
    "From the image above we can tell that we are making some progress here. The algorithm tries to denoise by making pixels neighbouring to each other \"blend\" together. However, it is also obvious that the image appears to have lower resolution since it is (motionally) blurrer, whereas the actual cause of that is same as why we have less noises... \n",
    "\n",
    "I will pause our experiment here since we've already figured out a way to \"denoise\" the image by generalizing the energy equation, whereas the undermined image quality is caused by the algorithm of changing pixel value. I will make this a topic of my exploration section later on, where we can try to figure out how to further improve our image quality. Thank you pepe, we will see you in the exploration section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. Graphical Representation\n",
    "\n",
    "![problem 2.1 image](Images/p21.png)\n",
    "\n",
    "## 2.1 For the Bayesian network show above, draw the corresponding Markov Random Field (MRF), and write out the joint probability using potential functions.  You do not need to specify the functions themselves, only which arguments they take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first moralize the directed graph by simply dropping the arrows from all edges and then connecting the only unmarried coparents of node `d`, which is `a` and `b` as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"206pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 206.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 202,-256 202,4 -4,4\"/>\r\n",
       "<!-- A -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>A</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- B -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>B</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- A&#45;&#45;B -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>A&#45;&#45;B</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.0658,-217.811C81.8405,-206.07 69.1304,-189.893 59.9109,-178.159\"/>\r\n",
       "</g>\r\n",
       "<!-- C -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>C</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"166\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">c</text>\r\n",
       "</g>\r\n",
       "<!-- A&#45;&#45;C -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>A&#45;&#45;C</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.361,-218.155C127.052,-206.276 141.972,-189.697 152.659,-177.824\"/>\r\n",
       "</g>\r\n",
       "<!-- D -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>D</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\r\n",
       "</g>\r\n",
       "<!-- A&#45;&#45;D -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>A&#45;&#45;D</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.518,-215.871C101.749,-188.578 100.254,-135.52 99.4842,-108.189\"/>\r\n",
       "</g>\r\n",
       "<!-- B&#45;&#45;D -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>B&#45;&#45;D</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.3186,-145.465C67.7701,-133.865 79.2691,-118.082 87.7131,-106.492\"/>\r\n",
       "</g>\r\n",
       "<!-- E -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>E</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- B&#45;&#45;E -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>B&#45;&#45;E</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.9165,-144.055C39.6148,-133.049 35.3291,-118.764 32.0367,-107.789\"/>\r\n",
       "</g>\r\n",
       "<!-- F -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>F</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- C&#45;&#45;F -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>C&#45;&#45;F</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.236,-143.697C168.011,-132.846 169.006,-118.917 169.778,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- G -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>G</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- D&#45;&#45;G -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>D&#45;&#45;G</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C84.8345,-61.456 77.1103,-46.4367 71.3043,-35.1473\"/>\r\n",
       "</g>\r\n",
       "<!-- H -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>H</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- D&#45;&#45;H -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>D&#45;&#45;H</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.35,-72.7646C113.165,-61.456 120.89,-46.4367 126.696,-35.1473\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1b1b97ba390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## plot the UDG corresponding to the Bayes net:\n",
    "dot = Graph()\n",
    "dot.node('A', 'a')\n",
    "dot.node('B', 'b')\n",
    "dot.node('C', 'c')\n",
    "dot.node('D', 'd')\n",
    "dot.node('E', 'e')\n",
    "dot.node('F', 'f')\n",
    "dot.node('G', 'g')\n",
    "dot.node('H', 'h')\n",
    "dot.edges(['AB', 'AC', 'AD', 'BD', 'BE', 'CF', 'DG', 'DH'])\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the joint probability distribution should be very simple to come up with:\n",
    "\n",
    "$$\n",
    "p(X) = \\frac{1}{Z} \\psi_{a,b,d} (a, b, d) \\psi_{a, c}(a, c) \\psi_{c, f}(c, f) \\psi_{b, e}(b, e) \\psi_{d, g}(d, g) \\psi_{d, h}(d, h)\n",
    "$$\n",
    "\n",
    "where $Z$ is a normalizing constant defined as:\n",
    "\n",
    "$$\n",
    "Z = \\sum_{X \\in \\{ a, b, ..., h\\}} \\psi_{a,b,d} (a, b, d) \\psi_{a, c}(a, c) \\psi_{c, f}(c, f) \\psi_{b, e}(b, e) \\psi_{d, g}(d, g) \\psi_{d, h}(d, h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Now specify the Bayes net as a factor graph.  Again write the expression for the joint probability, but using factor functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two possible ways to draw the factor graph: we can either have the factor graph from the UDG of our Bayes net, or directly from the Bayes net. Since the latter one preserve more information regarding the marginal independence of the nodes in the graph, we shall go with that way. \n",
    "\n",
    "First of all let's have the joint distribution of the original Bayes net as below:\n",
    "\n",
    "$$\n",
    "p(X) = p(f|c)p(c|a)p(g|d)p(d|a, b)p(h|d)p(e|b)p(a)p(b)\n",
    "$$\n",
    "And then we shall draw the factor graph according to the distribution:\n",
    "\n",
    "![factor graph p2.2](Images/p22.jpg)\n",
    "\n",
    "Sorry for the sketchy handwriting, I could not use `graphviz` this time since there were some compatibility problems on my pc to have different shapes for the nodes.\n",
    "\n",
    "And the factor function would just be:\n",
    "\n",
    "$$\n",
    "p(X) = f_1(f, c) f_2(c, a) f_3(g, d) f_4(d, a, b) f_5(h, d) f_6(e, b) f_7(b) f_8(a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Express the following Bayes net (from the sprinkler example) in two different factor graphs.  For each network, write the factors as a function of the conditional probabilties and specify the joint probability.\n",
    "\n",
    "![p2.3 image](Images/p23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get two different factor graphs, we can first moralize the Bayes net to have an UDG. And then, we may have two graphs with one corresponding to the Bayes net directly, and another corresponding to the UDG we have. Let's first take a look at the factor graph deriving from the UDG of the Bayes net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From UDG to factor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"90pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 90.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 86,-256 86,4 -4,4\"/>\r\n",
       "<!-- S -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>S</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">S</text>\r\n",
       "</g>\r\n",
       "<!-- R -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>R</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">R</text>\r\n",
       "</g>\r\n",
       "<!-- S&#45;&#45;R -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>S&#45;&#45;R</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M23.7517,-215.888C21.9542,-205.542 19.9053,-192.063 19,-180 17.8026,-164.045 17.8026,-159.955 19,-144 19.9053,-131.937 21.9542,-118.458 23.7517,-108.112\"/>\r\n",
       "</g>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- S&#45;&#45;T -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>S&#45;&#45;T</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.6356,-216.411C38.099,-205.252 43.9586,-190.604 48.412,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- J -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>J</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">J</text>\r\n",
       "</g>\r\n",
       "<!-- R&#45;&#45;J -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>R&#45;&#45;J</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-71.6966C27,-60.8463 27,-46.9167 27,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&#45;R -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>T&#45;&#45;R</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.3644,-144.411C43.901,-133.252 38.0414,-118.604 33.588,-107.47\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1b1b97a4438>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p23 = Graph()\n",
    "p23.node('S', 'S')\n",
    "p23.node('R', 'R')\n",
    "p23.node('T', 'T')\n",
    "p23.node('J', 'J')\n",
    "p23.edges(['SR', 'ST', 'TR', 'RJ'])\n",
    "p23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the factor graph of this is rather straightforward, which basically comes from the joint probability of the MRF as below:\n",
    "$$\n",
    "p(X) = \\psi_{S, T, R}(S, T, R) \\psi_{R, J}(R, J)\n",
    "$$\n",
    "\n",
    "And this tells us the factor graph as well as its joint probability:\n",
    "\n",
    "![factor graph from UDG](Images/p23a.jpg)\n",
    "\n",
    "$$ \n",
    "p(X) = f_1(S, T, R) f_2(R, J)\n",
    "$$\n",
    "\n",
    "Where the factors can be defined as:\n",
    "\n",
    "$$\n",
    "f_1 = \\psi_{S, T, R}(S, T, R) = p(T|S,R)p(S)p(R), \\space f_2 = \\psi_{R, J}(R, J) = p(J|R)p(R)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Bayes net to factor graph\n",
    "\n",
    "As in the previous part, we need to first come up with the joint probability of the Bayes net in order to setup the factor graph. The joint distribution coming from the Bayes net can be expressed as below:\n",
    "\n",
    "$$\n",
    "p(X) = p(T|S,R)p(J|R)p(S)p(R)\n",
    "$$\n",
    "\n",
    "From the equation above, we may then derive the factor graph along with its joint probability equation.\n",
    "\n",
    "![bayes factor graph](Images/p23b.jpg)\n",
    "\n",
    "$$\n",
    "p(X) = f_1(S,T,R)f_2(R,J)f_3(S)f_4(R)\n",
    "$$\n",
    "\n",
    "Where the factors can be defined as:\n",
    "\n",
    "$$\n",
    "f_1 = p(T|S,R), \\space f_2 = p(J|R), \\space f_3 = p(S), \\space f_4 = p(R)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3. The Sum Product Algorithm\n",
    "\n",
    "Consider the following factor graph:\n",
    "\n",
    "![problem 3 factor graph](Images/p3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Apply the sum-product algorithm to compute the all messages when none of the variables are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply the sum-product algorithm to compute all messages of this factor graph, let's set node `a` to be the root  node, and node `b` and `d` will thus become the leaf nodes. Let's first start with the direction from leaf nodes to the root node.\n",
    "\n",
    "leaves $\\rightarrow$ root:\n",
    "\n",
    "$\n",
    "\\mu_{d \\rightarrow f_2}(d) = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow c}(d) = \\sum_d f_2(d, c) \n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_1}(c) = \\mu_{f_2 \\rightarrow c}(d)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{b \\rightarrow f_1}(b) = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow a}(b, c) = \\sum_{b, c} f_1(b, c) \\mu_{b \\rightarrow f_1}(b) \\mu_{c \\rightarrow f_1}(c)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we shall go in the direction from root node to leaf nodes.\n",
    "\n",
    "root $\\rightarrow$ leaves: \n",
    "\n",
    "$\n",
    "\\mu_{a \\rightarrow f_1}(a) = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow c}(a, b) = \\sum_{a, b} f_1(a, b, c) \\mu_{b \\rightarrow f_1}(b) \\mu_{a \\rightarrow f_1}(a)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_2}(c) = \\mu_{f_1 \\rightarrow c}(a, b)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow d}(c) = \\sum_c f_2(c, d) \\mu_{c \\rightarrow f_2}(c)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute the marginal probability $p(c)$, expressing it in terms of the messages you derived in the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to expression `8.63` from Bishop, the marginal probability of $x$ can be expressed as\n",
    "$$\n",
    "p(x) = \\prod_{s \\in ne(x)} [\\sum_{X_s} F_s(x, X_s)]\n",
    "$$\n",
    "$$\n",
    "= \\prod_{s \\in ne(x)} \\mu_{f_s \\rightarrow x} (x) \n",
    "$$\n",
    "\n",
    "Therefore, the expression of marginal probability $p(c)$ would be\n",
    "$$\n",
    "p(c) = \\mu_{f_2 \\rightarrow c}(d) \\mu_{f_1 \\rightarrow c}(a, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Verify that the marginal is the correct expression substituting in the message definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From part 3.1 above, we already know that:\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow c}(d) = \\sum_d f_2(d, c) \n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow c}(a, b) = \\sum_{a, b} f_1(a, b, c) \\mu_{b \\rightarrow f_1}(b) \\mu_{a \\rightarrow f_1}(a)\n",
    "$\n",
    "\n",
    "Therefore, by substituting the message definitions above, the marginal will finally become:\n",
    "\n",
    "$$\n",
    "p(c) = [\\sum_{a, b} f_1(a, b, c)] \\mu_{b \\rightarrow f_1}(b) \\mu_{a \\rightarrow f_1}(a) [\\sum_d f_2(d, c)] \n",
    "$$\n",
    "$$\n",
    "= [\\sum_{a, b} f_1(a, b, c)] [\\sum_d f_2(d, c)]\n",
    "$$\n",
    "$$\n",
    "= \\sum_a \\sum_b \\sum_d f_1(a, b, c) f_2(d, c)\n",
    "$$\n",
    "where $f_1(a, b, c) f_2(d, c)$ is the factor function of the factor graph above, and the final expression we get is just the marginal expression derived from that equation. \n",
    "\n",
    "Therefore the marginal we get is the correct expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider adding a loop to the graph.\n",
    "\n",
    "![factor graph with loop](Images/p3loop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Explore the consequences of applying the sum-product algorithm to this graph. Can the algorithm still be applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's come to the conclusion at first: NO, the algorithm CANNOT be applied in this case. The general idea of this is that by having a loop, the final experssion for marginal probability having the message definitions substituded will also contain a loop. Now we shall take a quick look at the expression of our marginal on `c`, as it might be quite a good example to demonstrate this. \n",
    "\n",
    "First of all, let's take a look at all the messages in the graph given node `a` is the root:\n",
    "\n",
    "leaf $\\rightarrow$ root:\n",
    "\n",
    "$\n",
    "\\mu_{d \\rightarrow f_2}(d) = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow b}(c, d) = \\sum_{c, d} f_2(b, c, d) \\mu_{c \\rightarrow f_2}(c) \\mu_{d \\rightarrow f_2}(d)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow c}(b, d) = \\sum_{b, d} f_2(b, c, d) \\mu_{b \\rightarrow f_2}(b) \\mu_{d \\rightarrow f_2}(d)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{b \\rightarrow f_1}(b) = \\mu_{f_2 \\rightarrow b}(c, d)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_1}(c) = \\mu_{f_2 \\rightarrow c}(b, d)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow a}(b, c) = \\sum_{b, c} f_1(a, b, c) \\mu_{b \\rightarrow f_1}(b) \\mu_{c \\rightarrow f_1}(c)\n",
    "$\n",
    "\n",
    "root $\\rightarrow$ leaf:\n",
    "\n",
    "$\n",
    "\\mu_{a \\rightarrow f_1}(a) = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow b}(a, c) = \\sum_{a, c} f_1(a, b, c) \\mu_{c \\rightarrow f_1}(c) \\mu_{a \\rightarrow f_1}(a)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_1 \\rightarrow c}(a, b) = \\sum_{a, b} f_1(a, b, c) \\mu_{b \\rightarrow f_1}(b) \\mu_{a \\rightarrow f_1}(a)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{b \\rightarrow f_2}(b) = \\mu_{f_1 \\rightarrow b}(a, c)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_2}(c) = \\mu_{f_1 \\rightarrow c}(a, b)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{f_2 \\rightarrow d}(b, c) = \\sum_{b, c} f_2(b, c, d) \\mu_{b \\rightarrow f_2}(b) \\mu_{c \\rightarrow f_2}(c)\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then by using the sum-product algorithm, the mariginal probability of `c`, $p(c)$ should be:\n",
    "\n",
    "$$\n",
    "p(c) = \\mu_{f_2 \\rightarrow c}(b, d) \\mu_{f_1 \\rightarrow c}(a, b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= [\\sum_{b, d} f_2(b, c, d)] \\mu_{b \\rightarrow f_2}(b) \\mu_{d \\rightarrow f_2}(d) [\\sum_{a, b} f_1(a, b, c)] \\mu_{b \\rightarrow f_1}(b) \\mu_{a \\rightarrow f_1}(a)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= [\\sum_{b, d} f_2(b, c, d)] \\mu_{f_1 \\rightarrow b}(a, c) [\\sum_{a, b} f_1(a, b, c)] \\mu_{f_2 \\rightarrow b}(c, d) \n",
    "$$\n",
    "\n",
    "$$\n",
    "= [\\sum_{b, d} f_2(b, c, d)] [\\sum_{a, c} f_1(a, b, c)] \\mu_{c \\rightarrow f_1}(c) \\mu_{a \\rightarrow f_1}(a) [\\sum_{a, b} f_1(a, b, c)] [\\sum_{c, d} f_2(b, c, d)] \\mu_{c \\rightarrow f_2}(c) \\mu_{d \\rightarrow f_2}(d)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas \n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_2}(c) = \\mu_{f_1 \\rightarrow c}(a, b)\n",
    "$,\n",
    "\n",
    "and\n",
    "\n",
    "$\n",
    "\\mu_{c \\rightarrow f_1}(c) = \\mu_{f_2 \\rightarrow c}(b, d)\n",
    "$\n",
    "\n",
    "which indicates we have a loop here. Therefore the equation can not be solved, and thus the algorithm cannot be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "So in Excercise 1, we did some practices on the denoising of binary images as well as greyscale images with MRF as introduced in `Chapter 8` of Bishop. By the end of `8.3.3`, the textbook also mentions how belief propogation with sum-product and max-product algorithm can be a more effective algorithm for finding high probability solutions. Trying to improve the denoised image quality from my part 1.5, I did some researches on how the two algorithms can be applied to greyscale image denoising. However, given limited knowledge and resources about belief propogation with continous variables, I finally decided to make my exploration focused on binary images. \n",
    "\n",
    "In my exploration, I will go through the important steps of how to setup a denoising algorithm based on belief propogation as below:\n",
    "\n",
    "1. Have a UDG as a graphical model for image processing.  \n",
    "2. Setup a factorial graph corresponding to the graphical model above. Define the factors as well as the variables.  \n",
    "3. Based on the factorial graph, setup the joint probability distribution $p(X)$.  \n",
    "4. Define the belief propogation based on the sum-product and max-product algorithm as the iterative update function of our algorithm.  \n",
    "5. Describe how to apply the update function to achieve denoising on binary images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDG as a graphical model for image processing\n",
    "\n",
    "As in exercise 1 above, we still make the assumption that the causes of noises are independent to each other. Therefore, a simple undirected graphical model for image denoising should just look like Figure 8.31 from Bishop as provided below:\n",
    "\n",
    "![udg for image denoising](Images/p4udg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the UDG above, it should be pretty simple to construct a corresponding factor graph as below:\n",
    "\n",
    "![factor graph for image denoising](Images/p4factor.png)\n",
    "\n",
    "In this case, we have two factors as following: $f_i(x_i, y_i)$ and $f_{i, j}(x_i, x_j)$. \n",
    "\n",
    "$f_i(x_i, y_i)$ describes the factor between the pixel and its neighbouring pixels, whereas $f_{i, j}(x_i, x_j)$ describes the factor between the pixel and its corresponded observable node. Given a binary image with pixel value $\\in [0, 1]$, we shall define the factors as a $2 \\times 2$ matrix as below: \n",
    "\n",
    "$$f_i(x_i, y_i) = \\begin{bmatrix} 1 & 1 - \\eta \\\\ 1 - \\eta & 1 \\end{bmatrix} $$\n",
    "\n",
    "$$f_{i, j}(x_i, x_j) = \\begin{bmatrix} 1 & 1 - \\beta \\\\ 1 - \\beta & 1 \\end{bmatrix} $$\n",
    "\n",
    "Where $\\eta$ and $\\beta$ represents a positive floating constant ranging from $[0, 1]$. We take the two constants as parameters to define our function. An alternative way to express the above factors can be achieve through setting up potential functions, which, similarly, will just be: \n",
    "\n",
    "$$\\psi_i(x_i, y_i) = \\begin{bmatrix} 1 & 1 - \\eta \\\\ 1 - \\eta & 1 \\end{bmatrix} $$\n",
    "\n",
    "$$\\psi_{i, j}(x_i, x_j) = \\begin{bmatrix} 1 & 1 - \\beta \\\\ 1 - \\beta & 1 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint probability \n",
    "\n",
    "Given the factor graph above, let's briefly take a look  at what the joint probability of our image denoising model should look like: \n",
    "\n",
    "$$\n",
    "p(X) = [\\prod_{i,j} \\psi_{i,j}(x_i, x_j)] [\\prod_i \\psi(x_i, y_i)], \\space j \\in nbr(i)\n",
    "$$\n",
    "\n",
    "Then without applying the belief propogation algorithm, a \"raw\" marginal probability $p(x_i)$ on one pixel `xi` would become\n",
    "\n",
    "$$\n",
    "p(x_i) = \\sum_{i, j \\in nbr(i)} [[\\prod_{i,j} \\psi_{i,j}(x_i, x_j)] [\\prod_i \\psi(x_i, y_i)]]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update function with belief propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've obtained the marginal probability expression on one variable, a more efficient way in the form of message transmitting between neighbouring variables can be done as suggested in exercise 3 with belief propogation. For simplicity, the message definitions will be using potential functions instead of the factors since all factors are pairwise and we don't need to worry above trinity or above. \n",
    "\n",
    "For a pixel variable $x_i$, and all its neigbours $x_j$, along with the observation on the respective pixel $y_i$, the marginal probability of $x_i$ with belief propogation is just:\n",
    "\n",
    "$$\n",
    "p(x_i) = \\mu_{y_i \\rightarrow x_i}(y_i) [\\prod_{i, j \\in nbr(i)} \\mu_{x_j \\rightarrow x_i} (x_j)]\n",
    "$$\n",
    "\n",
    "where the definition of messages passing to the variable is \n",
    "\n",
    "$\n",
    "\\mu_{y_i \\rightarrow x_i}(y_i) = \\sum_{y_i} \\psi_i (x_i, y_i) = \\psi_i (x_i, y_i)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mu_{x_j \\rightarrow x_i} (x_j) = \\sum_{x_j} \\psi_{i, j}(x_i, x_j)\n",
    "$\n",
    "\n",
    "This allows us to separate the messages sent from different variables, and ultimately have a more efficient way to calculate the marginal probability. The equation above will become the update function for each variable during each iteration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update function in use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously in Exercise 1 we used the energy function along with its difference as a criterion of the quality of a variable. With belief propogation, we can do something quite the same. \n",
    "\n",
    "- First of all, we shall pick a random pixel $x_i$ from the image and then check its opposite color given that we are inspecting a binary image.  \n",
    "- We compare the marginal probability of current pixel value as well as the opposite one by using the potential function above, and determine if the new value promotes a higher probability.  \n",
    "- If the new value has a higher probability, we shall take the result, and pass the message corresponding to it, $\\mu_{x_i \\rightarrow x_j} (x_i)$, to all its neighbours $x_j$ with the updating function we previously define. To completely update all relevant pixels, we need to call the updating function recursively on the neighbours until the entire image is updated.  \n",
    "- If the marginal probability is not higher than the original one, we can still accept the result with a probability in the same mannar as we did it with simulated annealing. If the result is accepted, we udpate the whole image as in the previous condition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  To avoid writing a whole chapter, I will only implement the marginal probability along with the potential functions as below. The complete integration will not be covered in my exploration section as I'm still trying to figure out how to implement the updating function.  \n",
    "  My major concern here is how to avoid synchonization without using any lock/semaphore since the expansion of th updating process might overlap, and I'm not sure how to handle such situation. Feel free to give me helpful comment on how to get it done, I'd love to make this an individual project of mine once this problem is solved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retrieving a message according to the given parameters\n",
    "## v: indicating which potential function we are applying here\n",
    "## v = 0: comparing to original observation; v = 1: comparing to neighbours\n",
    "## we assume the nbr is a list of indices of k's neighbours\n",
    "def get_msg (pixels, obsv, nbr, k, beta, eta, v):\n",
    "    if v == 0: \n",
    "        potential = [[1, 1 - eta][1 - eta, 1]]\n",
    "        return potential[pixels[k], obsv[k]]\n",
    "    else:\n",
    "        potential = [[1, 1 - beta][1 - beta, 1]]\n",
    "        output = 0\n",
    "        for j in nbr:\n",
    "            output += potential[pixels[k], pixels[j]]\n",
    "        return output\n",
    "    \n",
    "def marginal_prob (pixels, nbr, k, yk, beta, eta):\n",
    "    ## initialize with muykxk\n",
    "    output = get_msg(pixels, obsv, nbr, k, beta, eta, 0)\n",
    "    for j in nbr:\n",
    "        ## muxjxk, again we assume get_nbr retrieves a list of indices of j's neighbours\n",
    "        msg = get_msg(pixels, obsv, get_nbr(j), j, beta, eta, 1)\n",
    "        output *= msg\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of exploration part. \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
